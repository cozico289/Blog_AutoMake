import streamlit as st
import os
import dotenv
import uuid
import hashlib
import logging
from typing import Optional, Tuple, Dict
from datetime import datetime
import threading
import psutil
from typing import Optional, Tuple, Dict, Any
from TextCustomizationModule import customize_text
from SeoNContentAnalysisModule import SEOContentAnalyzer
from Utilities import (
    validate_api_keys,
    format_message_history,
    calculate_token_usage,
    generate_session_summary,
    sanitize_input,
    create_error_message,
    log_error,
    cleanup_session,
    get_system_status,
    optimize_response
)

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage, AIMessage

from rag_methods import (
    load_doc_to_db, 
    load_url_to_db,
    stream_llm_response,
    stream_llm_rag_response,
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# ìƒìˆ˜ ì •ì˜
MODELS = [
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "anthropic/claude-3-5-sonnet-20240620",
    "google/gemini-1.5-flash",    
]

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    try:
        initial_states = {
            "session_id": str(uuid.uuid4()),
            "password_correct": False,
            "messages": [
                {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”!"},
                {"role": "assistant", "content": "ì–´ë–¤ ì£¼ì œë¡œ ê¸€ì„ ì‘ì„±í• ê¹Œìš”?"}
            ],
            "rag_sources": [],
            "current_response": "",
            "use_customization": False,
            "use_seo": False,
            "current_text": "",
            "error_log": [],
            "system_status": get_system_status()
        }
        
        for key, value in initial_states.items():
            if key not in st.session_state:
                st.session_state[key] = value
                
    except Exception as e:
        log_error(e, "init_session_state")
        st.error("ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def verify_api_keys() -> Tuple[str, str, str, Dict[str, bool]]:
    """API í‚¤ ê²€ì¦ ë° ë°˜í™˜"""
    api_keys = {
        "openai": st.session_state.get('openai_api_key', os.getenv("OPENAI_API_KEY", "")),
        "anthropic": st.session_state.get('anthropic_api_key', os.getenv("ANTHROPIC_API_KEY", "")),
        "google": st.session_state.get('google_api_key', os.getenv("GOOGLE_API_KEY", ""))
    }
    
    validation_result = validate_api_keys(
        api_keys["openai"],
        api_keys["anthropic"],
        api_keys["google"]
    )
    
    return api_keys["openai"], api_keys["anthropic"], api_keys["google"], validation_result

def setup_page():
    """í˜ì´ì§€ ì„¤ì •"""
    st.set_page_config(
        page_title="ë¸”ë¡œê·¸ ìë™ìƒì„± ì•±", 
        page_icon="ğŸ“š", 
        layout="centered", 
        initial_sidebar_state="expanded"
    )
    st.html("""<h2 style="text-align: center;">ğŸ“šğŸ” <i> ë¸”ë¡œê·¸ ìë™ìƒì„± ë´‡ </i> ğŸ¤–ğŸ’¬</h2>""")

def setup_sidebar() -> Tuple[str, bool]:
    """ì‚¬ì´ë“œë°” ì„¤ì •"""
    with st.sidebar:
        # API í‚¤ ì…ë ¥ ë° ê²€ì¦
        openai_api_key, anthropic_api_key, google_api_key, api_validation = verify_api_keys()
        
        with st.expander("ğŸ”‘ API í‚¤ ì„¤ì •"):
            st.text_input("OpenAI API Key", value=openai_api_key, type="password", key="openai_api_key")
            st.text_input("Anthropic API Key", value=anthropic_api_key, type="password", key="anthropic_api_key")
            st.text_input("Google API Key", value=google_api_key, type="password", key="google_api_key")
        
        st.divider()
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í•„í„°ë§
        available_models = [
            model for model in MODELS 
            if ("openai" in model and api_validation["openai"]) or 
               ("anthropic" in model and api_validation["anthropic"]) or 
               ("google" in model and api_validation["google"])
        ]
        
        if available_models:
            selected_model = st.selectbox("ğŸ¤– ëª¨ë¸ ì„ íƒ", available_models, key="model")
        else:
            st.warning("â¬…ï¸ ê³„ì†í•˜ì‹œë ¤ë©´ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”...")
            return None, False
        
        # RAG ì„¤ì •
        cols = st.columns(2)
        with cols[0]:
            use_rag = st.toggle(
                "RAG ì‚¬ìš©",
                value="vector_db" in st.session_state,
                key="use_rag",
                disabled="vector_db" not in st.session_state,
            )
        with cols[1]:
            if st.button("ì „ì²´ ì‚­ì œ", type="primary"):
                cleanup_session()
                st.rerun()
        
        # RAG ì†ŒìŠ¤ ê´€ë¦¬
        st.header("RAG ì†ŒìŠ¤:")
        setup_rag_sources()
        
        # ë¶€ê°€ ê¸°ëŠ¥ ì„¤ì •
        st.divider()
        setup_additional_features()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        if st.checkbox("ì‹œìŠ¤í…œ ìƒíƒœ ë³´ê¸°"):
            show_system_status()
        
        # ë„ì›€ë§
        add_sidebar_help()
        
        return selected_model, use_rag

def setup_rag_sources():
    """RAG ì†ŒìŠ¤ ì„¤ì •"""
    st.file_uploader(
        "ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ",
        type=["pdf", "txt", "docx", "md"],
        accept_multiple_files=True,
        on_change=load_doc_to_db,
        key="rag_docs",
    )
    
    st.text_input(
        "ğŸŒ URL ë„£ê¸°",
        placeholder="https://example.com",
        on_change=load_url_to_db,
        key="rag_url",
    )
    
    with st.expander(f"ğŸ“š ë¬¸ì„œ ì† DB ({len(st.session_state.get('rag_sources', []))})"):
        st.write(st.session_state.get('rag_sources', []))

def setup_additional_features():
    """ë¶€ê°€ ê¸°ëŠ¥ ì„¤ì •"""
    cols = st.columns(2)
    with cols[0]:
        st.toggle("ì»¤ìŠ¤í…€ ê¸°ëŠ¥", value=False, key="use_customization")
    with cols[1]:
        st.toggle("SEO ë¶„ì„", value=False, key="use_seo")

def show_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
    status = st.session_state.system_status
    cols = st.columns(2)
    with cols[0]:
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{status['memory_usage']:.1f}MB")
        st.metric("CPU ì‚¬ìš©ë¥ ", f"{status['cpu_usage']}%")
    with cols[1]:
        st.metric("ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ", f"{status['disk_usage']}%")
        st.metric("í™œì„± ìŠ¤ë ˆë“œ", status['active_threads'])

def get_llm_model(model_name: str, api_keys: Dict[str, str]) -> Optional[object]:
    """LLM ëª¨ë¸ ì´ˆê¸°í™”"""
    try:
        model_type = model_name.split("/")[0]
        model_id = model_name.split("/")[-1]
        
        model_configs = {
            "openai": {
                "class": ChatOpenAI,
                "params": {
                    "api_key": api_keys["openai"],
                    "model_name": model_id
                }
            },
            "anthropic": {
                "class": ChatAnthropic,
                "params": {
                    "api_key": api_keys["anthropic"],
                    "model": model_id
                }
            },
            "google": {
                "class": ChatGoogleGenerativeAI,
                "params": {
                    "api_key": api_keys["google"],
                    "model": model_id
                }
            }
        }
        
        config = model_configs.get(model_type)
        if not config:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
            
        return config["class"](
            **config["params"],
            temperature=0.3,
            streaming=True
        )
        
    except Exception as e:
        log_error(e, "get_llm_model")
        st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {create_error_message(e)}")
        return None

def process_message(prompt: str, llm_model, use_rag: bool):
    """ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
    try:
        # ì…ë ¥ ì •ì œ
        prompt = sanitize_input(prompt)
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì •
        estimated_tokens = calculate_token_usage(prompt)
        if estimated_tokens > 4000:  # ì˜ˆì‹œ ì œí•œê°’
            st.warning("ì…ë ¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë” ì§§ì€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # assistant ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            st.session_state.message_placeholder = message_placeholder

            messages = [
                HumanMessage(content=m["content"]) if m["role"] == "user" 
                else AIMessage(content=m["content"]) 
                for m in st.session_state.messages
            ]

            # ì‘ë‹µ ìƒì„±
            response_text = ""
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
                if use_rag:
                    for chunk in stream_llm_rag_response(llm_model, messages):
                        response_text += chunk
                        message_placeholder.markdown(response_text)
                else:
                    for chunk in stream_llm_response(llm_model, messages):
                        response_text += chunk
                        message_placeholder.markdown(response_text)

                if response_text:
                    # ì‘ë‹µ ìµœì í™” ë° ì €ì¥
                    optimized_response = optimize_response(response_text)
                    st.session_state.original_response = optimized_response
                    st.session_state.current_text = optimized_response
                    
                    # ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë” ì—…ë°ì´íŠ¸
                    message_placeholder.markdown(optimized_response)
                    
                    # ì»¤ìŠ¤í„°ë§ˆì´ì§• ì ìš©
                    if st.session_state.use_customization:
                        customized_text = customize_text(optimized_response, llm_model)
                        if customized_text and customized_text != optimized_response:
                            st.session_state.current_text = customized_text
                            # ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                            st.session_state.messages[-1]["content"] = customized_text
                            message_placeholder.markdown(customized_text)

                    # SEO ë¶„ì„
                    if st.session_state.use_seo and not use_rag:
                        with st.spinner("SEO ë¶„ì„ ì¤‘..."):
                            seo_result = run_seo_analysis(st.session_state.current_text, llm_model)
                            if seo_result and "ê°œì„ ëœ_í…ìŠ¤íŠ¸" in seo_result:
                                st.session_state.current_text = seo_result["ê°œì„ ëœ_í…ìŠ¤íŠ¸"]
                                st.session_state.messages[-1]["content"] = seo_result["ê°œì„ ëœ_í…ìŠ¤íŠ¸"]
                                message_placeholder.markdown(seo_result["ê°œì„ ëœ_í…ìŠ¤íŠ¸"])

                    # ì„¸ì…˜ ìš”ì•½ ì—…ë°ì´íŠ¸
                    st.session_state.session_summary = generate_session_summary()

    except Exception as e:
        log_error(e, "process_message")
        st.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {create_error_message(e)}")
        
def run_seo_analysis(text: str, llm_model) -> Dict[str, Any]:  # llm_model ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
    """SEO ë¶„ì„ ì‹¤í–‰"""
    try:
        st.divider()
        st.subheader("ğŸ” SEO ë¶„ì„")

        col1, col2 = st.columns([3, 1])
        with col1:
            keyword = st.text_input(
                "ì£¼ìš” í‚¤ì›Œë“œ",
                help="ë¶„ì„í•  ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                placeholder="ì˜ˆ: ë§›ì§‘, ì—¬í–‰, ë¦¬ë·° ë“±",
                key="seo_keyword"
            )

        with col2:
            analyze_button = st.button(
                "ë¶„ì„ ì‹œì‘",
                type="primary",
                key="seo_analysis_button"
            )

        if analyze_button and keyword:
            with st.spinner("SEO ë¶„ì„ ì¤‘..."):
                seo_analyzer = SEOContentAnalyzer()
                keyword = sanitize_input(keyword)
                
                # í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
                trends = seo_analyzer.analyze_keyword_trends(keyword)
                
                # ë©”íŠ¸ë¦­ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ì›”ê°„ ê²€ìƒ‰ëŸ‰", f"{trends['ì›”ê°„ ê²€ìƒ‰ëŸ‰']:,}íšŒ")
                with col2:
                    st.metric("ì „ì›” ëŒ€ë¹„ ì¦ê°", f"{trends['ì „ì›” ëŒ€ë¹„ ì¦ê°']:.1f}%")
                
                # SEO ì ìˆ˜ ë¶„ì„
                seo_score = seo_analyzer.calculate_seo_score(text, keyword)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("SEO ì´ì ", f"{seo_score['ì´ì ']}/100")
                with col2:
                    st.metric("SEO ë“±ê¸‰", seo_score['ë“±ê¸‰'])
                with col3:
                    st.metric(
                        "í‚¤ì›Œë“œ ë°€ë„",
                        f"{seo_score['ì„¸ë¶€ ì ìˆ˜']['í‚¤ì›Œë“œ ë°€ë„ ì ìˆ˜']:.1f}%"
                    )
                
                # íƒœê·¸ ì¶”ì²œ
                tags = seo_analyzer._generate_tags(text, keyword)
                st.write("### ì¶”ì²œ íƒœê·¸")
                st.write(", ".join(f"#{tag}" for tag in tags))
                
                # ê°œì„  ì œì•ˆ
                recommendations = seo_analyzer._analyze_content_structure(text)
                st.write("### ê°œì„  ì œì•ˆ")
                for suggestion in recommendations["ê°œì„  í•„ìš” ì‚¬í•­"]:
                    if suggestion:
                        st.info(suggestion)

                # SEO ìµœì í™”ëœ í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­
                prompt = f"""
                ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ SEO ìµœì í™”í•´ì£¼ì„¸ìš”:
                1. í‚¤ì›Œë“œ '{keyword}'ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë°°ì¹˜
                2. ì œëª©ê³¼ ë¶€ì œëª© êµ¬ì¡° ìµœì í™”
                3. ì ì ˆí•œ í‚¤ì›Œë“œ ë°€ë„ ìœ ì§€
                4. ê°€ë…ì„± ê°œì„ 
                
                ì›ë³¸ í…ìŠ¤íŠ¸:
                {text}
                """
                
                with st.spinner("SEO ìµœì í™”ëœ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘..."):
                    optimized_response = llm_model.invoke(prompt).content
                    
                    return {
                        "ë¶„ì„_ê²°ê³¼": seo_score,
                        "ì¶”ì²œ_íƒœê·¸": tags,
                        "ê°œì„ _ì œì•ˆ": recommendations["ê°œì„  í•„ìš” ì‚¬í•­"],
                        "ê°œì„ ëœ_í…ìŠ¤íŠ¸": optimized_response
                    }
                
        elif analyze_button:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    except Exception as e:
        log_error(e, "run_seo_analysis")
        st.error(f"SEO ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {create_error_message(e)}")
        return None
    
def check_password(input_password: str) -> bool:
    """ë¹„ë°€ë²ˆí˜¸ í™•ì¸"""
    try:
        correct_hash = '0ffe1abd1a08215353c233d6e009613e95eec4253832a761af28ff37ac5a150c'  # ë¹„ë°€ë²ˆí˜¸: '1111'
        return hashlib.sha256(input_password.encode()).hexdigest() == correct_hash
    except Exception as e:
        log_error(e, "check_password")
        return False

def handle_password_protection():
    """ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ ì²˜ë¦¬"""
    if not st.session_state.password_correct:
        st.markdown("### ğŸ”’ ì ‘ê·¼ ì œì–´")
        password_input = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
        
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("í™•ì¸", type="primary"):
                if check_password(password_input):
                    st.session_state.password_correct = True
                    st.success("ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.error("ì˜ëª»ëœ ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return False
    return True

def add_sidebar_help():
    """ì‚¬ì´ë“œë°” ë„ì›€ë§ ì¶”ê°€"""
    with st.sidebar:
        st.divider()
        st.markdown("### ğŸ” ë„ì›€ë§")
        
        with st.expander("ì£¼ìš” ê¸°ëŠ¥"):
            st.markdown("""
            - ğŸ’¡ RAGë¥¼ ì‚¬ìš©í•˜ë©´ ì—…ë¡œë“œí•œ ë¬¸ì„œë‚˜ URLì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ë‹µí•©ë‹ˆë‹¤
            - ğŸ”„ ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ìœ¼ë¡œ ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - âœ¨ ì‘ë‹µ í…ìŠ¤íŠ¸ëŠ” ì´ëª¨ì§€, ë¬¸ì²´, ê¸¸ì´, ë…í•´ ìˆ˜ì¤€ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            """)
        
        with st.expander("ì‚¬ìš© íŒ"):
            st.markdown("""
            1. **RAG ì‚¬ìš©í•˜ê¸°**:
               - PDF, TXT, DOCX, MD íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥
               - URLì„ í†µí•œ ì›¹í˜ì´ì§€ ì°¸ì¡° ê°€ëŠ¥
               - ìµœëŒ€ 10ê°œì˜ ë¬¸ì„œ ë™ì‹œ ì°¸ì¡° ê°€ëŠ¥
            
            2. **ì»¤ìŠ¤í„°ë§ˆì´ì§•**:
               - ì´ëª¨ì§€ ì¶”ê°€ë¡œ ê¸€ ìƒë™ê° í–¥ìƒ
               - ë¬¸ì²´ ë³€ê²½ìœ¼ë¡œ í†¤ì•¤ë§¤ë„ˆ ì¡°ì •
               - ê¸¸ì´ ì¡°ì ˆë¡œ ì½˜í…ì¸  ëŸ‰ ìµœì í™”
               - ë…í•´ ìˆ˜ì¤€ ì¡°ì •ìœ¼ë¡œ íƒ€ê²Ÿ ë…ìì¸µ ë§ì¶¤í™”
            
            3. **SEO ìµœì í™”**:
               - í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™”
               - ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„
               - ë§ì¶¤í˜• íƒœê·¸ ì¶”ì²œ
               - ì»¨í…ì¸  êµ¬ì¡° ê°œì„  ì œì•ˆ
            """)
        
        with st.expander("ë¬¸ì œ í•´ê²°"):
            st.markdown("""
            - â“ API í‚¤ ê´€ë ¨ ë¬¸ì œëŠ” ê° ì œê³µì‚¬ì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸
            - ğŸ”„ ì‘ë‹µì´ ëŠë¦° ê²½ìš° ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„
            - ğŸ“ ì˜¤ë¥˜ ë°œìƒì‹œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œ íŒŒì•…
            - ğŸ›  ê¸°ìˆ ì  ë¬¸ì œëŠ” ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜
            """)

def update_system_metrics():
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    try:
        st.session_state.system_status = get_system_status()
    except Exception as e:
        log_error(e, "update_system_metrics")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì´ˆê¸° ì„¤ì •
        init_session_state()
        setup_page()
        
        # ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ ì²´í¬
        if not handle_password_protection():
            return
        
        # ì‚¬ì´ë“œë°” ì„¤ì •
        selected_model, use_rag = setup_sidebar()
        if not selected_model:
            return
        
        # API í‚¤ í™•ì¸ ë° ëª¨ë¸ ì´ˆê¸°í™”
        openai_key, anthropic_key, google_key, _ = verify_api_keys()
        api_keys = {
            "openai": openai_key,
            "anthropic": anthropic_key,
            "google": google_key
        }
        
        llm_model = get_llm_model(selected_model, api_keys)
        if not llm_model:
            return
        
        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if prompt := st.chat_input(
            "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            key="chat_input",
            max_chars=2000
        ):
            process_message(prompt, llm_model, use_rag)
            
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        update_system_metrics()
        
    except Exception as e:
        log_error(e, "main")
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {create_error_message(e)}")
        if st.button("ì•± ì´ˆê¸°í™”", type="primary"):
            cleanup_session()
            st.rerun()

if __name__ == "__main__":
    main()